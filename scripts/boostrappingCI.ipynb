{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current kernel is ML\n"
     ]
    }
   ],
   "source": [
    "#Setup\n",
    "import pickle\n",
    "import logging\n",
    "import pathlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import openpyxl\n",
    "import sklearn\n",
    "from aidp.data.groupings import AdVsDlbGrouping, AdVsAllGrouping, DlbVsAllGrouping, ConVsAllGrouping, AdVsConGrouping, DlbVsConGrouping\n",
    "from abc import ABC, abstractmethod\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix\n",
    "\n",
    "#Version Control \n",
    "skvers = sklearn.__version__\n",
    "#NEED to use the same ML conda version (scikit0learn==0.19.0)\n",
    "if skvers != \"0.21.3\" :\n",
    "    !pip install scikit-learn==0.19.0\n",
    "    import sklearn\n",
    "\n",
    "#Paths\n",
    "mk=\"ADDLB021023\" #Same as V2 and Verbose\n",
    "folder_name=\"ADDLB_021023_finalModel\" #contains training and testing\n",
    "script_path=\"/media/mcuser/Data1/RChen/SupportVectorMachine\"\n",
    "mod_path=script_path+'/resources/models/'+mk+'/dmri'\n",
    "xl_path='/media/mcuser/Data1/RChen/SupportVectorMachine/ADDLB_021023_finalModel'\n",
    "os.chdir(mod_path)\n",
    "os.getcwd()\n",
    "print(\"Current kernel is\", os.environ['CONDA_DEFAULT_ENV'])\n",
    "\n",
    "#Load Dataframes\n",
    "df_tr=pd.read_excel(xl_path+'/r_ADDLB_NP_train_021023_ADDLB021023.xlsx', header=0, index_col=\"Subject\")\n",
    "df_te=pd.read_excel(xl_path+'/r_ADDLB_NP_test_021023_ADDLB021023.xlsx', header=0, index_col=\"Subject\")\n",
    "keep_columns=[\"GroupID\",\"dmri_ad_v_dlb (AD Probability)\", \"dmri_ad_v_con (AD Probability)\", \n",
    "              \"dmri_dlb_v_con (DLB Probability)\", \"dmri_ad_v_all (AD Probability)\", \n",
    "              \"dmri_dlb_v_all (DLB Probability)\", \"dmri_con_v_dem (CON Probability)\"]\n",
    "df_tr_trim=df_tr[keep_columns]\n",
    "df_te_trim=df_te[keep_columns]\n",
    "\n",
    "#Dictionary for label redefining (1 for 'positive' class (higher probability), 0 for 'negative' class)\n",
    "avd_dict = {\"GroupID\": {2:0}} #drop 3, 1=AD, 0=DLB\n",
    "dvc_dict = {\"GroupID\": {3:0, 2:1}} #drop 1, 1=DLB, 0=CON\n",
    "avc_dict = {\"GroupID\": {3:0}} #drop 2, 1=AD, 0=CON\n",
    "avb_dict = {\"GroupID\": {2:0, 3:0}}\n",
    "dvb_dict = {\"GroupID\": {1:\"A\", 3:\"A\", 2:\"B\"}}\n",
    "cvb_dict = {\"GroupID\": {1:\"A\", 2:\"A\", 3:\"B\"}}\n",
    "tf_dict = {\"GroupID\": {\"B\":1, \"A\":0}}\n",
    "dict_list = [avd_dict, dvc_dict, avc_dict, avb_dict, dvb_dict, cvb_dict, tf_dict]\n",
    "\n",
    "def conmatscores(y_true, y_pred):\n",
    "    y_pred_class = np.array(np.round(y_pred))\n",
    "    cm = confusion_matrix(y_true, y_pred_class) #assume y_pred is fed in as probabilities\n",
    "    # print(cm)\n",
    "    tn, fp, fn, tp = cm[0][0], cm[0][1], cm[1][0], cm[1][1]\n",
    "    # tn, fp, fn, tp = cm([0,1,0,1], [1,1,1,0]).ravel()\n",
    "    total=(tn+fp+fn+tp)\n",
    "    accuracy = (tp+tn)/(total)\n",
    "    sens = tp / (tp+fn)\n",
    "    spec = tn / (fp+tn)\n",
    "    ppv = tp / (tp+fp)\n",
    "    npv = tn / (tn+fn)\n",
    "    auc = roc_auc_score(y_true, y_pred)\n",
    "    return accuracy, sens, spec, ppv, npv, auc\n",
    "\n",
    "def bootstrapper(Y_true, Y_pred, savename: str, r_seed=42, n_bootstraps=1000):\n",
    "    acc_bs_scores = []\n",
    "    sens_bs_scores = []\n",
    "    spec_bs_scores = []\n",
    "    ppv_bs_scores = []\n",
    "    npv_bs_scores = []\n",
    "    auc_bs_scores = []\n",
    "    rng = np.random.RandomState(r_seed)\n",
    "    for i in range(n_bootstraps):\n",
    "        indices = rng.randint(0, len(Y_pred), len(Y_pred))\n",
    "        if len(np.unique(Y_true[indices])) < 2:\n",
    "            continue\n",
    "        acc, sens, spec, ppv, npv, auc = conmatscores(Y_true[indices], Y_pred[indices])\n",
    "        acc_bs_scores.append(acc)\n",
    "        sens_bs_scores.append(sens)\n",
    "        spec_bs_scores.append(spec)\n",
    "        ppv_bs_scores.append(ppv)\n",
    "        npv_bs_scores.append(npv)\n",
    "        auc_bs_scores.append(auc)\n",
    "    df_report = pd.DataFrame( {\"Accuracy\": acc_bs_scores, \"Sensitivity\": sens_bs_scores, \"Specificity\": spec_bs_scores,\n",
    "                               \"PPV\": ppv_bs_scores, \"NPV\": npv_bs_scores, \"AUC\": auc})\n",
    "    df_report.to_excel(script_path+'/'+folder_name+'/mlreport/'+savename+'_report.xlsx', index=0)\n",
    "\n",
    "\n",
    "def report_mean_ci(dfname: str):\n",
    "    df = pd.read_excel(script_path+'/'+folder_name+'/mlreport/'+dfname+'_report.xlsx')\n",
    "    df_sum=pd.DataFrame(index=df.columns, columns=[\"Mean\", \"Lower\", \"Upper\"])\n",
    "    for metric in df.columns:\n",
    "        metric_array = np.array(df[metric])\n",
    "        metric_array.sort()\n",
    "        mean_met = np.mean(metric_array)\n",
    "        lower_met = metric_array[int(.025*len(metric_array))]\n",
    "        upper_met = metric_array[int(0.975*len(metric_array))]\n",
    "        # print(metric, mean_met, lower_met, upper_met)\n",
    "        df_sum.loc[str(metric)] = [mean_met, lower_met, upper_met]\n",
    "        \n",
    "    df_sum.to_excel(script_path+'/'+folder_name+'/mlreport/'+dfname+'_report_summary.xlsx')\n",
    "    \n",
    "def test_scores(Y_true, Y_pred):\n",
    "    accuracy, sens, spec, ppv, npv, auc = conmatscores(Y_true, Y_pred)\n",
    "    print (\"accuracy\", accuracy*100, \"sens\", sens*100, \"spec\", spec*100, \"ppv\", ppv*100, \"npv\", npv*100, \"auc\", auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1]\n",
      "(0.8840579710144928, 0.9230769230769231, 0.25, 0.9523809523809523, 0.16666666666666666, 0.7692307692307693)\n"
     ]
    }
   ],
   "source": [
    "#### PATH\n",
    "xl_path2='/media/mcuser/Data1/RChen/SupportVectorMachine'\n",
    "df_path=pd.read_excel(xl_path+'/r_ADDLB_path_021023_ADDLB021023.xlsx', header=0, index_col=\"Subject\")\n",
    "df_path_Y_true=df_path[[\"GroupID\"]]\n",
    "df_path2_Y_true=df_path_Y_true.replace({2:0})\n",
    "print(np.unique(df_path2_Y_true))\n",
    "df_path2_Y_pred=df_path[[\"dmri_ad_v_dlb (AD Probability)\"]]\n",
    "\n",
    "print(conmatscores(df_path2_Y_true, df_path2_Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testdf = pd.read_excel(script_path+'/'+folder_name+'/mlreport/'+'addlb_train'+'_report.xlsx')\n",
    "# testdf.columns\n",
    "# score_summary = []\n",
    "# df_sum = pd.DataFrame(index=testdf.columns, columns=[\"Mean\", \"Lower\", \"Upper\"])\n",
    "# for metric in testdf.columns:\n",
    "#     extracted_metric=np.array(testdf[metric])\n",
    "#     extracted_metric.sort()\n",
    "#     mean_met = np.mean(extracted_metric)\n",
    "#     lower_b = extracted_metric[int(.025*len(extracted_metric))]\n",
    "#     upper_b = extracted_metric[int(.975*len(extracted_metric))]\n",
    "#     df_sum.loc[str(metric)] = [mean_met, lower_b, upper_b]\n",
    "#     # display(df_sum)\n",
    "#     print(metric, mean_met, lower_b, upper_b)\n",
    "# df_sum.to_excel(script_path+'/'+folder_name+'/mlreport/'+'addlb_train'+'_report_summary.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 85.71428571428571 sens 78.57142857142857 spec 92.85714285714286 ppv 91.66666666666666 npv 81.25 auc 0.9591836734693877\n"
     ]
    }
   ],
   "source": [
    "##### AD vs DLB\n",
    "advdlb=pickle.load(open('ad_v_dlb.pkl', 'rb'))\n",
    "df_tr_trim_addlb = df_tr_trim[df_tr_trim.GroupID!=3]\n",
    "df_tr_trim_addlb_redef = df_tr_trim_addlb.replace(dict_list[0])\n",
    "Y_true_tr_addlb = np.array(df_tr_trim_addlb_redef.GroupID)\n",
    "Y_pred_tr_addlb = np.array(df_tr_trim_addlb_redef[\"dmri_ad_v_dlb (AD Probability)\"])\n",
    "df_te_trim_addlb = df_te_trim[df_te_trim.GroupID!=3]\n",
    "df_te_trim_addlb_redef = df_te_trim_addlb.replace(dict_list[0])\n",
    "Y_true_te_addlb = np.array(df_te_trim_addlb_redef.GroupID)\n",
    "Y_pred_te_addlb = np.array(df_te_trim_addlb_redef[\"dmri_ad_v_dlb (AD Probability)\"])\n",
    "\n",
    "bootstrapper(Y_true_tr_addlb, Y_pred_tr_addlb, savename=\"addlb_train\")\n",
    "bootstrapper(Y_true_te_addlb, Y_pred_te_addlb, savename=\"addlb_test\")\n",
    "report_mean_ci(dfname=\"addlb_train\")\n",
    "report_mean_ci(dfname=\"addlb_test\")\n",
    "\n",
    "test_scores(Y_true_te_addlb, Y_pred_te_addlb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 82.45614035087719 sens 75.0 spec 89.65517241379311 ppv 87.5 npv 78.78787878787878 auc 0.9298029556650247\n"
     ]
    }
   ],
   "source": [
    "##### DLB vs CON\n",
    "dlbvcon=pickle.load(open('dlb_v_con.pkl', 'rb'))\n",
    "df_tr_trim_dlbcon = df_tr_trim[df_tr_trim.GroupID!=1]\n",
    "df_tr_trim_dlbcon_redef = df_tr_trim_dlbcon.replace(dict_list[1])\n",
    "Y_true_tr_dlbcon = np.array(df_tr_trim_dlbcon_redef.GroupID)\n",
    "Y_pred_tr_dlbcon = np.array(df_tr_trim_dlbcon_redef[\"dmri_dlb_v_con (DLB Probability)\"])\n",
    "df_te_trim_dlbcon = df_te_trim[df_te_trim.GroupID!=1]\n",
    "df_te_trim_dlbcon_redef = df_te_trim_dlbcon.replace(dict_list[1])\n",
    "Y_true_te_dlbcon = np.array(df_te_trim_dlbcon_redef.GroupID)\n",
    "Y_pred_te_dlbcon = np.array(df_te_trim_dlbcon_redef[\"dmri_dlb_v_con (DLB Probability)\"])\n",
    "\n",
    "bootstrapper(Y_true_tr_dlbcon, Y_pred_tr_dlbcon, savename=\"dlbcon_train\")\n",
    "bootstrapper(Y_true_te_dlbcon, Y_pred_te_dlbcon, savename=\"dlbcon_test\")\n",
    "report_mean_ci(dfname=\"dlbcon_train\")\n",
    "report_mean_ci(dfname=\"dlbcon_test\")\n",
    "\n",
    "test_scores(Y_true_te_dlbcon, Y_pred_te_dlbcon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 94.73684210526315 sens 92.85714285714286 spec 96.55172413793103 ppv 96.29629629629629 npv 93.33333333333333 auc 0.9581280788177341\n"
     ]
    }
   ],
   "source": [
    "##### AD vs CON\n",
    "advcon=pickle.load(open('ad_v_con.pkl', 'rb'))\n",
    "df_tr_trim_adcon = df_tr_trim[df_tr_trim.GroupID!=2]\n",
    "df_tr_trim_adcon_redef = df_tr_trim_adcon.replace(dict_list[2])\n",
    "Y_true_tr_adcon = np.array(df_tr_trim_adcon_redef.GroupID)\n",
    "Y_pred_tr_adcon = np.array(df_tr_trim_adcon_redef[\"dmri_ad_v_con (AD Probability)\"])\n",
    "df_te_trim_adcon = df_te_trim[df_te_trim.GroupID!=2]\n",
    "df_te_trim_adcon_redef = df_te_trim_adcon.replace(dict_list[2])\n",
    "Y_true_te_adcon = np.array(df_te_trim_adcon_redef.GroupID)\n",
    "Y_pred_te_adcon = np.array(df_te_trim_adcon_redef[\"dmri_ad_v_con (AD Probability)\"])\n",
    "\n",
    "bootstrapper(Y_true_tr_adcon, Y_pred_tr_adcon, savename=\"adcon_train\")\n",
    "bootstrapper(Y_true_te_adcon, Y_pred_te_adcon, savename=\"adcon_test\")\n",
    "report_mean_ci(dfname=\"adcon_train\")\n",
    "report_mean_ci(dfname=\"adcon_test\")\n",
    "\n",
    "test_scores(Y_true_te_adcon, Y_pred_te_adcon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 92.94117647058823 sens 82.14285714285714 spec 98.24561403508771 ppv 95.83333333333334 npv 91.80327868852459 auc 0.9730576441102756\n"
     ]
    }
   ],
   "source": [
    "##### AD vs DLB/CON\n",
    "advall=pickle.load(open('ad_v_all.pkl', 'rb'))\n",
    "df_tr_trim_advb = df_tr_trim\n",
    "df_tr_trim_advb_redef = df_tr_trim_advb.replace(dict_list[3])\n",
    "Y_true_tr_advb = np.array(df_tr_trim_advb_redef.GroupID)\n",
    "Y_pred_tr_advb = np.array(df_tr_trim_advb_redef[\"dmri_ad_v_all (AD Probability)\"])\n",
    "# print(Y_true_tr_advb.shape, Y_pred_tr_advb.shape)\n",
    "df_te_trim_advb = df_te_trim\n",
    "df_te_trim_advb_redef = df_te_trim_advb.replace(dict_list[3])\n",
    "Y_true_te_advb = np.array(df_te_trim_advb_redef.GroupID)\n",
    "Y_pred_te_advb = np.array(df_te_trim_advb_redef[\"dmri_ad_v_all (AD Probability)\"])\n",
    "\n",
    "bootstrapper(Y_true_tr_advb, Y_pred_tr_advb, savename=\"advb_train\")\n",
    "bootstrapper(Y_true_te_advb, Y_pred_te_advb, savename=\"advb_test\")\n",
    "report_mean_ci(dfname=\"advb_train\")\n",
    "report_mean_ci(dfname=\"advb_test\")\n",
    "\n",
    "test_scores(Y_true_te_advb, Y_pred_te_advb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 72.94117647058823 sens 25.0 spec 96.49122807017544 ppv 77.77777777777779 npv 72.36842105263158 auc 0.9191729323308271\n"
     ]
    }
   ],
   "source": [
    "##### DLB vs AD/CON\n",
    "dlbvall=pickle.load(open('dlb_v_all.pkl', 'rb'))\n",
    "df_tr_trim_dlbvb = df_tr_trim\n",
    "df_tr_trim_dlbvb_redef = df_tr_trim_dlbvb.replace(dict_list[4]).replace(dict_list[6])\n",
    "Y_true_tr_dlbvb = np.array(df_tr_trim_dlbvb_redef.GroupID)\n",
    "Y_pred_tr_dlbvb = np.array(df_tr_trim_dlbvb_redef[\"dmri_dlb_v_all (DLB Probability)\"])\n",
    "df_te_trim_dlbvb = df_te_trim\n",
    "df_te_trim_dlbvb_redef = df_te_trim_dlbvb.replace(dict_list[4]).replace(dict_list[6])\n",
    "Y_true_te_dlbvb = np.array(df_te_trim_dlbvb_redef.GroupID)\n",
    "Y_pred_te_dlbvb = np.array(df_te_trim_dlbvb_redef[\"dmri_dlb_v_all (DLB Probability)\"])\n",
    "\n",
    "bootstrapper(Y_true_tr_dlbvb, Y_pred_tr_dlbvb, savename=\"dlbvb_train\")\n",
    "bootstrapper(Y_true_te_dlbvb, Y_pred_te_dlbvb, savename=\"dlbvb_test\")\n",
    "report_mean_ci(dfname=\"dlbvb_train\")\n",
    "report_mean_ci(dfname=\"dlbvb_test\")\n",
    "\n",
    "test_scores(Y_true_te_dlbvb, Y_pred_te_dlbvb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 85.88235294117646 sens 79.3103448275862 spec 89.28571428571429 ppv 79.3103448275862 npv 89.28571428571429 auc 0.9470443349753694\n"
     ]
    }
   ],
   "source": [
    "##### CON vs AD/DLB\n",
    "convall=pickle.load(open('con_v_dem.pkl', 'rb'))\n",
    "df_tr_trim_convb = df_tr_trim\n",
    "df_tr_trim_convb_redef = df_tr_trim_convb.replace(dict_list[5]).replace(dict_list[6])\n",
    "Y_true_tr_convb = np.array(df_tr_trim_convb_redef.GroupID)\n",
    "Y_pred_tr_convb = np.array(df_tr_trim_convb_redef[\"dmri_con_v_dem (CON Probability)\"])\n",
    "df_te_trim_convb = df_te_trim\n",
    "df_te_trim_convb_redef = df_te_trim_convb.replace(dict_list[5]).replace(dict_list[6])\n",
    "Y_true_te_convb = np.array(df_te_trim_convb_redef.GroupID)\n",
    "Y_pred_te_convb = np.array(df_te_trim_convb_redef[\"dmri_con_v_dem (CON Probability)\"])\n",
    "\n",
    "bootstrapper(Y_true_tr_convb, Y_pred_tr_convb, savename=\"convb_train\")\n",
    "bootstrapper(Y_true_te_convb, Y_pred_te_convb, savename=\"convb_test\")\n",
    "report_mean_ci(dfname=\"convb_train\")\n",
    "report_mean_ci(dfname=\"convb_test\")\n",
    "\n",
    "test_scores(Y_true_te_convb, Y_pred_te_convb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
